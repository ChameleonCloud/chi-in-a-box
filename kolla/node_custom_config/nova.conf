[DEFAULT]
# TODO: [jca 2019-02-08]
# This might not be necessary; it is unclear why we have this setting disabled.
vif_plugging_is_fatal = False
vif_plugging_timeout = 0

[filter_scheduler]
available_filters = nova.scheduler.filters.all_filters
available_filters = blazarnova.scheduler.filters.blazar_filter.BlazarFilter
enabled_filters = BlazarFilter,RetryFilter,ComputeCapabilitiesFilter,ImagePropertiesFilter,JsonFilter
max_instances_per_host = 1
# We don't schedule based on anything other than the Blazar reservation, really. So we don't
# need to periodically ask the nodes about their current state.
# https://docs.openstack.org/nova/latest/configuration/config.html#filter_scheduler.track_instance_changes
track_instance_changes = False
# https://docs.openstack.org/nova/latest/configuration/config.html#filter_scheduler.host_subset_size
host_subset_size = 9999999

[neutron]
# Increase timeout for Neutron to reduce probability of error during launches
# of a lot of nodes at once.
timeout = 300

# TODO: [jca 2019-01-24]
# Backwards compatibility for Ocata - can remove
# after upgrading past Queens.
[placement]
os_region_name = "{{ openstack_region_name }}"

[quota]
max_age = 0
until_refresh = 0
reservation_expire = 86400
# Remove quota limits for hosts; these are handled via Blazar
instances = -1
cores = -1
ram = -1

[scheduler]
host_manager = ironic_host_manager
# TODO: [jca 2019-02-08]
# This seems quite high. We potentially don't need to keep it this high.
# This is the value we have used in the past however.
max_attempts = 50

[serial_console]
base_url = wss://{{ kolla_external_fqdn }}:{{ nova_serialproxy_port }}/

[api]
vendordata_providers = DynamicJSON
vendordata_dynamic_targets = chameleon@http://127.0.0.1:8911

[vendordata_dynamic_auth]
auth_type = password
auth_url = "{{ openstack_keystone_auth_uri }}"
project_name = service
project_domain_id = default
username = {{ nova_keystone_user }}
user_domain_id = default
password = "{{ nova_keystone_password }}"
